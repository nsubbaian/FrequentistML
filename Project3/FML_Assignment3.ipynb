{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FML_Assignment3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7gi2TnuJ2IxROW3dJMrZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsubbaian/FrequentistML/blob/master/Project3/FML_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_oQMraZfDj0",
        "colab_type": "text"
      },
      "source": [
        "# **Frequentist Machine Learning Assigment 3: Model Assessment and Selection**\n",
        "\n",
        "Re-implement the example in section 7.10.2 using any simple, out of the box classifier\n",
        "(like K nearest neighbors from sci-kit). Reproduce the results for the incorrect and \n",
        "correct way of doing cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GhNfRoqe82p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "# Data simulating N = 50 samples in two equal-sized classes, and p = 5000 quantitative\n",
        "# predictors (standard Gaussian) that are independent of the class labels.\n",
        "# The true (test) error rate of any classifier is 50%.\n",
        "X = np.random.normal(0, 1, [50,5000])\n",
        "\n",
        "Y = np.concatenate([np.zeros(25),np.ones(25)])\n",
        "np.random.shuffle(Y)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OwBjARiiNc_",
        "colab_type": "text"
      },
      "source": [
        "### Results for the incorrect way of doing cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIYXgEdeiMhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1896a779-3d90-41bc-c391-c7a174207868"
      },
      "source": [
        "# Screen the predictors: find a subset of “good” predictors that show fairly strong (univariate) correlation with the class labels\n",
        "X_new = preprocessing.MinMaxScaler().fit_transform(X)\n",
        "X_new = SelectKBest(chi2, k=100).fit_transform(X_new, Y)\n",
        "\n",
        "# Using just this subset of predictors, build a multivariate classifier.\n",
        "neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "# Use cross-validation to estimate the unknown tuning parameters and to estimate the prediction error of the final model.\n",
        "CV = []\n",
        "kf = RepeatedKFold(n_splits=5, n_repeats=50)\n",
        "\n",
        "for train_index, test_index in kf.split(X_new):\n",
        "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "    neigh.fit(X_train, Y_train)\n",
        "    CV.append(1-neigh.score(X_test, Y_test))\n",
        "\n",
        "print(\"Average CV Error Rate:\", np.array(CV).mean())"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average CV Error Rate: 0.027199999999999995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI7IXMXviOGr",
        "colab_type": "text"
      },
      "source": [
        "### Results for the correct way of doing cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV7lnaWKiMsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b6072eb-2359-4efc-90af-df7575c7b228"
      },
      "source": [
        "# Divide the samples into K cross-validation folds (groups) at random.\n",
        "\n",
        "# For each fold k = 1, 2, . . . , K\n",
        "# 1. Find a subset of “good” predictors that show fairly strong (univariate) correlation with the class labels, using all of the samples except those in fold k.\n",
        "# 2. Using just this subset of predictors, build a multivariate classifier, using all of the samples except those in fold k.\n",
        "# 3. Use the classifier to predict the class labels for the samples in fold k.\n",
        "\n",
        "X = pd.DataFrame(data=X)\n",
        "Y = pd.DataFrame(data=Y)\n",
        "\n",
        "CV2 = []\n",
        "kf = RepeatedKFold(n_splits=5, n_repeats=50)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    X_new2 = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
        "    X_new2 = pd.DataFrame(data=X_new2)\n",
        "    selector = SelectKBest(chi2, k=100)\n",
        "    selector.fit_transform(X_new2, np.ravel(Y_train))\n",
        "    cols = selector.get_support(indices=True)\n",
        "    X_new2 = X_new2.iloc[:,cols]\n",
        "\n",
        "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
        "    neigh.fit(X_new2, np.ravel(Y_train))\n",
        "  \n",
        "    CV2.append(1-neigh.score(X_test.iloc[:,cols], np.ravel(Y_test)))\n",
        "\n",
        "print(\"Average CV Error Rate:\", np.array(CV2).mean())"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average CV Error Rate: 0.55\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}